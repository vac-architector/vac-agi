# активируй venv, если не активен
source ~/venvs/vac-gpu/.venv/bin/activate

# перейди в проект
cd /mnt/c/VAC/Private

# старт
python web_vac.py
# открой: http://127.0.0.1:5000/



Частые вопросы / подводные камни
Почему не faiss-gpu? Готовые колёса под CUDA 12 на PyPI нестабильны/редки. С твоим объёмом faiss-cpu достаточно быстрый. При желании поставим faiss-gpu через conda/mamba (проще), но это уже отдельный тред.

Где держать venv? Всегда на ext4 (домашняя WSL), а исходники могут оставаться на C:. Так избегаем OSError: [Errno 5].

Ollama и GPU: держи Ollama в Windows (у тебя 4090) — так он использует нативный драйвер. VAC в WSL ходит по http://localhost:11434.

Рефлексия: план минимально разрушителен: мы не трогаем кодовую базу, только чистим хлам venv на NTFS, создаём одно стабильное GPU-окружение на ext4, ставим корректные библиотеки (CUDA-torch, s-t, faiss-cpu, pypdf), проверяем CUDA и запускаем. Если захочешь — дальше можем собрать requirements-gpu.txt и маленький Makefile/скрипт ./dev.sh для авто-подъёма окружения одним шагом.